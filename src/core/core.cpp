#define NEKOCODE_FOUNDATION_CORE_CPP  // åŸºç›¤å‡¦ç†ã¨ã—ã¦regexä½¿ç”¨è¨±å¯
#include "nekocode/core.hpp"
#include "nekocode/formatters.hpp"
#include "nekocode/utf8_utils.hpp"
#include "nekocode/language_detection.hpp"
#include "nekocode/cpp_analyzer.hpp"
#include "nekocode/tree_sitter_analyzer.hpp"
#include "nekocode/pegtl_analyzer.hpp"
// #include "nekocode/analyzers/csharp_analyzer.hpp" // regexç‰ˆã¯å‰Šé™¤æ¸ˆã¿
#include "../analyzers/base_analyzer.hpp"
#include "../utils/file_size_reporter.hpp"
#include "hybrid_stack_manager.hpp"
#include <fstream>
#include <sstream>
#include <algorithm>
#include <execution>
#include <iostream>
#include <filesystem>
#include <regex>
#include <unordered_set>
#include <thread>
#include <nlohmann/json.hpp>
#include <mutex>
#include <atomic>
#include <numeric>

namespace nekocode {

//=============================================================================
// ğŸ§  NekoCodeCore::Impl - PIMPLå®Ÿè£…
//=============================================================================

class NekoCodeCore::Impl {
public:
    AnalysisConfig config_;
    PerformanceMetrics metrics_;
    std::unique_ptr<TreeSitterAnalyzer> tree_sitter_analyzer_;
    std::unique_ptr<PEGTLAnalyzer> pegtl_analyzer_;
    std::unique_ptr<CppAnalyzer> cpp_analyzer_;
    std::unique_ptr<LanguageDetector> language_detector_;
    std::unique_ptr<FileScanner> file_scanner_;
    ProgressCallback progress_callback_;
    std::atomic<bool> parallel_enabled_{true};
    std::atomic<uint32_t> thread_count_{0};
    std::atomic<uint32_t> io_threads_{4};     // ğŸ†• åŒæ™‚ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æ•°
    std::atomic<uint32_t> cpu_threads_{0};    // ğŸ†• è§£æã‚¹ãƒ¬ãƒƒãƒ‰æ•°
    mutable std::mutex metrics_mutex_;

    explicit Impl(const AnalysisConfig& config) 
        : config_(config)
        , tree_sitter_analyzer_(std::make_unique<TreeSitterAnalyzer>())
        , pegtl_analyzer_(std::make_unique<PEGTLAnalyzer>())
        , cpp_analyzer_(std::make_unique<CppAnalyzer>())
        , language_detector_(std::make_unique<LanguageDetector>())
        , file_scanner_(std::make_unique<FileScanner>(config)) 
    {
        thread_count_ = config.max_threads;
        io_threads_ = config.io_threads;
        cpu_threads_ = config.cpu_threads;
    }
};

//=============================================================================
// ğŸ—ï¸ NekoCodeCore Construction
//=============================================================================

NekoCodeCore::NekoCodeCore(const AnalysisConfig& config)
    : impl_(std::make_unique<Impl>(config)) {}

NekoCodeCore::~NekoCodeCore() = default;

NekoCodeCore::NekoCodeCore(NekoCodeCore&&) noexcept = default;
NekoCodeCore& NekoCodeCore::operator=(NekoCodeCore&&) noexcept = default;

//=============================================================================
// ğŸ“„ Single File Analysis
//=============================================================================

Result<AnalysisResult> NekoCodeCore::analyze_file(const FilePath& file_path) {
    auto [result, duration] = utils::measure_time([&]() -> Result<AnalysisResult> {
        // ğŸ¯ Hybrid Stack Manager ã«ã‚ˆã‚‹å·¨å¤§ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ
        HybridStackManager stack_mgr;
        
        return stack_mgr.analyze_with_smart_stack(file_path, [&]() -> Result<AnalysisResult> {
            // ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            auto content_result = utils::read_file(file_path);
            if (content_result.is_error()) {
                return Result<AnalysisResult>(content_result.error());
            }
            
            return analyze_content(content_result.value(), file_path.string());
        });
    });
    
    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆæ›´æ–°
    {
        std::lock_guard<std::mutex> lock(impl_->metrics_mutex_);
        impl_->metrics_.parsing_time += duration;
        impl_->metrics_.files_processed++;
    }
    
    return result;
}

Result<AnalysisResult> NekoCodeCore::analyze_content(const std::string& content, const std::string& filename) {
    try {
        // è¨€èªè‡ªå‹•æ¤œå‡º
        FilePath file_path(filename);
        Language detected_language = impl_->language_detector_->detect_language(file_path, content);
        
        // ğŸŒ³ Tree-sitterçµ±ä¸€è§£æ - å…¨è¨€èªå¯¾å¿œï¼
        AnalysisResult result;
        
        // ãƒ•ã‚¡ã‚¤ãƒ«åŸºæœ¬æƒ…å ±è§£æ
        result.file_info = analyze_file_structure(content, file_path);
        result.language = detected_language;
        
        if (impl_->config_.analyze_complexity) {
            result.complexity = analyze_complexity(content);
        }
        
        // ğŸ”¥ PEGTLè§£æï¼ˆå…¨è¨€èªçµ±ä¸€ãƒ»é«˜ç²¾åº¦ï¼‰
        if (detected_language == Language::JAVASCRIPT || 
            detected_language == Language::TYPESCRIPT || 
            detected_language == Language::CPP || 
            detected_language == Language::C ||
            detected_language == Language::PYTHON) {
            auto pegtl_result = impl_->pegtl_analyzer_->analyze(content, filename, detected_language);
            if (pegtl_result.is_success()) {
                auto pg_result = pegtl_result.value();
                result.classes = pg_result.classes;
                result.functions = pg_result.functions;
                result.imports = pg_result.imports;
                result.exports = pg_result.exports;
                if (impl_->config_.analyze_complexity) {
                    result.complexity = pg_result.complexity;
                }
                
                // ğŸ†• CRITICAL FIX: commented_linesé…åˆ—ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆæ¬ è½ã—ã¦ã„ãŸï¼ï¼‰
                result.commented_lines = pg_result.commented_lines;
                
                // ğŸš€ Phase 5: Universal Symbolsã‚’ã‚³ãƒ”ãƒ¼ï¼ˆå¿…é ˆï¼ï¼‰
                if (pg_result.universal_symbols) {
                    result.universal_symbols = pg_result.universal_symbols;
                    std::cerr << "[DEBUG core.cpp] Copied universal_symbols from PEGTL result" << std::endl;
                } else {
                    std::cerr << "[DEBUG core.cpp] No universal_symbols in PEGTL result" << std::endl;
                }
            }
        }
        
        // ğŸ”¥ PEGTLãŒæ—¢ã«ä¾å­˜é–¢ä¿‚ã¨è¤‡é›‘åº¦ã‚’è§£ææ¸ˆã¿
        // å¾“æ¥ã®æ­£è¦è¡¨ç¾ãƒ™ãƒ¼ã‚¹ãƒ»Tree-sitterãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã¯ä¸è¦
        
        // çµ±è¨ˆæ›´æ–°
        result.update_statistics();
        
        // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        {
            std::lock_guard<std::mutex> lock(impl_->metrics_mutex_);
            impl_->metrics_.lines_processed += result.file_info.total_lines;
            impl_->metrics_.bytes_processed += result.file_info.size_bytes;
        }
        
        return Result<AnalysisResult>(std::move(result));
        
    } catch (const std::exception& e) {
        return Result<AnalysisResult>(AnalysisError(ErrorCode::PARSING_ERROR, e.what()));
    }
}

Result<FileInfo> NekoCodeCore::get_file_info(const FilePath& file_path) {
    return utils::get_basic_file_info(file_path);
}

//=============================================================================
// ğŸŒ Multi-Language Analysis Implementation
//=============================================================================

Result<MultiLanguageAnalysisResult> NekoCodeCore::analyze_file_multilang(const FilePath& file_path) {
    auto [result, duration] = utils::measure_time([&]() -> Result<MultiLanguageAnalysisResult> {
        try {
            // ğŸ¯ Hybrid Stack Manager ã«ã‚ˆã‚‹å·¨å¤§ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ
            HybridStackManager stack_mgr;
            
            return stack_mgr.analyze_with_smart_stack(file_path, [&]() -> Result<MultiLanguageAnalysisResult> {
                // ğŸ¯ å¤§ãƒ•ã‚¡ã‚¤ãƒ«é€²æ—è¡¨ç¤ºï¼ˆClaude Codeå‘ã‘ï¼‰
                size_t file_size = 0;
                try {
                    file_size = std::filesystem::file_size(file_path);
                    if (FileSizeReporter::is_large_file(file_size)) {
                        FileSizeReporter::report_large_file_start(file_path.filename().string(), file_size);
                    }
                } catch (...) {
                    // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå–å¾—å¤±æ•—ã¯ç„¡è¦–ã—ã¦ç¶šè¡Œ
                }
                
                // UTF-8 safe file reading
                auto safe_content = utf8::read_file_safe_utf8(file_path.string());
                if (!safe_content.conversion_success) {
                    return Result<MultiLanguageAnalysisResult>(
                        AnalysisError(ErrorCode::FILE_NOT_FOUND, safe_content.error_message, file_path));
                }
                
                // è¨€èªè‡ªå‹•æ¤œå‡º
                Language detected_lang = impl_->language_detector_->detect_language(file_path, safe_content.content);
                
                auto analysis_result = analyze_content_multilang(safe_content.content, file_path.string(), detected_lang);
                
                // ğŸ¯ å¤§ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Œäº†é€šçŸ¥
                if (FileSizeReporter::is_large_file(file_size)) {
                    FileSizeReporter::report_large_file_complete(file_path.filename().string());
                }
                
                return analysis_result;
            });
            
        } catch (const std::exception& e) {
            return Result<MultiLanguageAnalysisResult>(
                AnalysisError(ErrorCode::PARSING_ERROR, e.what(), file_path));
        }
    });
    
    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆæ›´æ–°
    {
        std::lock_guard<std::mutex> lock(impl_->metrics_mutex_);
        impl_->metrics_.parsing_time += duration;
        impl_->metrics_.files_processed++;
    }
    
    return result;
}

Result<MultiLanguageAnalysisResult> NekoCodeCore::analyze_file_with_language(const FilePath& file_path, Language language) {
    auto [result, duration] = utils::measure_time([&]() -> Result<MultiLanguageAnalysisResult> {
        try {
            // UTF-8 safe file reading
            auto safe_content = utf8::read_file_safe_utf8(file_path.string());
            if (!safe_content.conversion_success) {
                return Result<MultiLanguageAnalysisResult>(
                    AnalysisError(ErrorCode::FILE_NOT_FOUND, safe_content.error_message, file_path));
            }
            
            return analyze_content_multilang(safe_content.content, file_path.string(), language);
            
        } catch (const std::exception& e) {
            return Result<MultiLanguageAnalysisResult>(
                AnalysisError(ErrorCode::PARSING_ERROR, e.what(), file_path));
        }
    });
    
    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆæ›´æ–°
    {
        std::lock_guard<std::mutex> lock(impl_->metrics_mutex_);
        impl_->metrics_.parsing_time += duration;
        impl_->metrics_.files_processed++;
    }
    
    return result;
}

Result<MultiLanguageAnalysisResult> NekoCodeCore::analyze_content_multilang(const std::string& content, 
                                                                            const std::string& filename, 
                                                                            Language language) {
    try {
        MultiLanguageAnalysisResult result;
        result.detected_language = language;
        
        // è¨€èªãŒä¸æ˜ãªå ´åˆã¯å†…å®¹ã‹ã‚‰æ¨å®š
        if (language == Language::UNKNOWN && !content.empty()) {
            result.detected_language = impl_->language_detector_->detect_by_content(content);
        }
        
        // è¨€èªåˆ¥è§£æå®Ÿè¡Œ
        switch (result.detected_language) {
            case Language::JAVASCRIPT:
            case Language::TYPESCRIPT: {
                // JavaScript/TypeScriptè§£æ
                auto js_result = analyze_content(content, filename);
                if (js_result.is_success()) {
                    result.js_result = js_result.value();
                    result.file_info = js_result.value().file_info;
                } else {
                    return Result<MultiLanguageAnalysisResult>(js_result.error());
                }
                break;
            }
            
            case Language::CPP:
            case Language::C: {
                // ğŸ”¥ PEGTLç‰ˆã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã‚’ä½¿ç”¨ï¼ˆClaude Codeæ”¯æ´ä½œæˆ¦ï¼‰
                auto analyzer = AnalyzerFactory::create_analyzer(result.detected_language);
                if (analyzer) {
                    auto analysis_result = analyzer->analyze(content, filename);
                    
                    // CppAnalysisResultã‚’ä½œæˆï¼ˆPEGTLçµæœã‹ã‚‰å¤‰æ›ï¼‰
                    CppAnalysisResult cpp_result;
                    cpp_result.file_info = analysis_result.file_info;
                    cpp_result.complexity = analysis_result.complexity;
                    
                    // ğŸ”¥ CRITICAL FIX: çµ±è¨ˆæƒ…å ±ã‚’ç›´æ¥ã‚³ãƒ”ãƒ¼ï¼ˆå¤‰æ›ã§å¤±ã‚ã‚Œã‚‹ã®ã‚’é˜²ãï¼‰
                    cpp_result.stats = analysis_result.stats;
                    
                    // ğŸ†• CRITICAL FIX: commented_linesé…åˆ—ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆæ¬ è½ã—ã¦ã„ãŸï¼ï¼‰
                    cpp_result.commented_lines = analysis_result.commented_lines;
                    
                    // ã‚¯ãƒ©ã‚¹ãƒ»é–¢æ•°æƒ…å ±ã‚’å¤‰æ›
                    for (const auto& cls : analysis_result.classes) {
                        // ãƒ‡ãƒãƒƒã‚°ã‚¯ãƒ©ã‚¹ã‚’é™¤å¤–
                        if (cls.name == "CPP_PEGTL_ANALYZER_CALLED") {
                            continue;
                        }
                        
                        CppClass cpp_class;
                        cpp_class.name = cls.name;
                        cpp_class.start_line = cls.start_line;
                        cpp_class.end_line = cls.end_line;
                        cpp_class.class_type = CppClass::CLASS; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                        
                        // ğŸ”¥ ãƒ¡ãƒ³ãƒå¤‰æ•°æƒ…å ±ã‚’å¤‰æ›
                        for (const auto& member : cls.member_variables) {
                            // MemberVariable -> string å¤‰æ›ï¼ˆCppClassã¯std::vector<std::string>ï¼‰
                            cpp_class.member_variables.push_back(member.name);
                        }
                        
                        cpp_result.cpp_classes.push_back(cpp_class);
                    }
                    
                    for (const auto& func : analysis_result.functions) {
                        CppFunction cpp_func;
                        cpp_func.name = func.name;
                        cpp_func.start_line = func.start_line;
                        cpp_func.end_line = func.end_line;
                        // CppFunctionã®return_typeã‚’ä½¿ç”¨
                        cpp_func.return_type = "auto"; // PEGTLã§ã¯å‹æ¨å®šãŒå›°é›£ãªã®ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                        // access_levelãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯å­˜åœ¨ã—ãªã„
                        cpp_result.cpp_functions.push_back(cpp_func);
                    }
                    
                    // ğŸ”¥ çµ±è¨ˆå†è¨ˆç®—ã¯ä¸è¦ï¼PEGTLçµæœã‚’ä¿¡é ¼
                    // cpp_result.update_statistics(); // â† ã“ã‚ŒãŒå•é¡Œã®åŸå› ã ã£ãŸï¼
                    
                    // ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›å‰Šé™¤ï¼ˆJSONå‡ºåŠ›ã«å¹²æ¸‰ã™ã‚‹ãŸã‚ï¼‰
                    // std::cerr << "âœ… Stats preserved: classes=" << cpp_result.stats.class_count 
                    //           << ", functions=" << cpp_result.stats.function_count << std::endl;
                    
                    result.cpp_result = cpp_result;
                    result.file_info = analysis_result.file_info;
                    
                    // std::cerr << "âœ… C++ PEGTL analyzer used successfully!" << std::endl;
                } else {
                    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®CppAnalyzer
                    auto cpp_result = impl_->cpp_analyzer_->analyze_cpp_file(content, filename);
                    result.cpp_result = cpp_result;
                    result.file_info = cpp_result.file_info;
                    // std::cerr << "âš ï¸  Fallback to old CppAnalyzer" << std::endl;
                }
                break;
            }
            
            case Language::CSHARP: {
                // ğŸ® Unity content detection + C# è§£æ
                // Unity analyzer ã‚’å„ªå…ˆçš„ã«è©¦è¡Œ
                auto analyzer = AnalyzerFactory::create_unity_analyzer_from_file(filename, content);
                
                if (analyzer) {
                    auto csharp_result = analyzer->analyze(content, filename);
                    result.csharp_result = csharp_result;
                    result.file_info = csharp_result.file_info;
                    
                    // Unity analyzer ãŒä½¿ç”¨ã•ã‚ŒãŸã‹ã‚’ãƒ­ã‚°å‡ºåŠ›
                    if (content.find("using UnityEngine") != std::string::npos || 
                        content.find(": MonoBehaviour") != std::string::npos) {
                        std::cerr << "ğŸ® Unity analyzer used for: " << filename << std::endl;
                    } else {
                        std::cerr << "âš™ï¸ C# PEGTL analyzer used for: " << filename << std::endl;
                    }
                } else {
                    // Unityåˆ¤å®šã«å¤±æ•—ã—ãŸå ´åˆã¯é€šå¸¸ã®C#ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã‚’ä½¿ç”¨
                    analyzer = AnalyzerFactory::create_analyzer(Language::CSHARP);
                    if (analyzer) {
                        auto csharp_result = analyzer->analyze(content, filename);
                        result.csharp_result = csharp_result;
                        result.file_info = csharp_result.file_info;
                        std::cerr << "âš™ï¸ C# PEGTL analyzer used (fallback) for: " << filename << std::endl;
                    } else {
                        std::cerr << "ERROR: Failed to create C# analyzer for: " << filename << std::endl;
                    }
                }
                break;
            }
            
            case Language::GO: {
                // ğŸ¹ Goè¨€èªè§£æï¼ˆGoroutine & Channel Detectionï¼‰
                auto analyzer = AnalyzerFactory::create_analyzer(result.detected_language);
                if (analyzer) {
                    auto go_result = analyzer->analyze(content, filename);
                    
                    // Goå›ºæœ‰ã®çµæœã‚’JSçµæœã¨ã—ã¦æ ¼ç´ï¼ˆå…±é€šæ§‹é€ ãŒãªã„ãŸã‚ï¼‰
                    result.js_result = go_result;
                    result.file_info = go_result.file_info;
                    
                    std::cerr << "ğŸ¹ Go analyzer used successfully for: " << filename << std::endl;
                } else {
                    std::cerr << "ERROR: Failed to create Go analyzer for: " << filename << std::endl;
                }
                break;
            }
            
            case Language::RUST: {
                // ğŸ¦€ Rustè¨€èªè§£æï¼ˆtrait, impl, macro Detectionï¼‰
                auto analyzer = AnalyzerFactory::create_analyzer(result.detected_language);
                if (analyzer) {
                    auto rust_result = analyzer->analyze(content, filename);
                    
                    // ğŸ”§ Rustå›ºæœ‰ã®çµæœã‚’æ­£ã—ã„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«æ ¼ç´
                    result.rust_result = rust_result;
                    result.file_info = rust_result.file_info;
                    
                    // Rust analyzer successfully created
                } else {
                    // Failed to create Rust analyzer
                }
                break;
            }
            
            case Language::UNKNOWN:
            default: {
                // ä¸æ˜ãªè¨€èªã®å ´åˆã¯JavaScriptã¨ã—ã¦è§£æã‚’è©¦è¡Œ
                auto js_result = analyze_content(content, filename);
                if (js_result.is_success()) {
                    result.js_result = js_result.value();
                    result.file_info = js_result.value().file_info;
                    result.detected_language = Language::JAVASCRIPT;
                } else {
                    return Result<MultiLanguageAnalysisResult>(
                        AnalysisError(ErrorCode::PARSING_ERROR, "Unknown language and JavaScript parsing failed"));
                }
                break;
            }
        }
        
        // ğŸ¯ å®Œå…¨è§£æãƒ¢ãƒ¼ãƒ‰: ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰æ¤œå‡ºã‚’å®Ÿè¡Œ
        if (impl_->config_.complete_analysis) {
            perform_complete_analysis(result, filename);
        }
        
        return Result<MultiLanguageAnalysisResult>(std::move(result));
        
    } catch (const std::exception& e) {
        return Result<MultiLanguageAnalysisResult>(
            AnalysisError(ErrorCode::PARSING_ERROR, e.what()));
    }
}

//=============================================================================
// ğŸ¯ Complete Analysis Implementation - å®Œå…¨è§£æå‡¦ç†
//=============================================================================

void NekoCodeCore::perform_complete_analysis(MultiLanguageAnalysisResult& result, const std::string& filename) {
    try {
        // ğŸ Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å‘¼ã³å‡ºã—ã¦ãƒ‡ãƒƒãƒ‰ã‚³ãƒ¼ãƒ‰æ¤œå‡º
        std::string command = "python3 src/tools/universal_deadcode_analyzer.py \"" + filename + "\" --complete";
        
        // ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
        FILE* pipe = popen(command.c_str(), "r");
        if (!pipe) {
            std::cerr << "âš ï¸ Failed to execute dead code analysis for: " << filename << std::endl;
            return;
        }
        
        // çµæœèª­ã¿å–ã‚Š
        std::string output;
        char buffer[128];
        while (fgets(buffer, sizeof(buffer), pipe) != nullptr) {
            output += buffer;
        }
        pclose(pipe);
        
        // JSONçµæœã‚’æ¢ã™ï¼ˆPythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯è£…é£¾ä»˜ãã§å‡ºåŠ›ï¼‰
        size_t json_start = output.rfind("{");
        if (json_start != std::string::npos) {
            // JSONéƒ¨åˆ†ã‚’æŠ½å‡º
            std::string json_str = output.substr(json_start);
            size_t json_end = json_str.find_last_of("}");
            if (json_end != std::string::npos) {
                json_str = json_str.substr(0, json_end + 1);
                
                try {
                    // JSONãƒ‘ãƒ¼ã‚¹
                    nlohmann::json dead_code_result = nlohmann::json::parse(json_str);
                    
                    // dead_codeæƒ…å ±ã‚’å–å¾—
                    if (dead_code_result.contains("dead_code") && 
                        dead_code_result["dead_code"].contains("status")) {
                        
                        // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«è©³ç´°æƒ…å ±ã‚’ä¿å­˜
                        std::string dead_code_json = dead_code_result["dead_code"].dump();
                        
                        // è¨€èªåˆ¥ã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ä¿å­˜
                        if (result.cpp_result.has_value()) {
                            result.cpp_result->file_info.metadata["dead_code"] = dead_code_json;
                        } 
                        if (result.js_result.has_value()) {
                            result.js_result->file_info.metadata["dead_code"] = dead_code_json;
                        } 
                        if (result.csharp_result.has_value()) {
                            result.csharp_result->file_info.metadata["dead_code"] = dead_code_json;
                        } 
                        if (result.rust_result.has_value()) {
                            result.rust_result->file_info.metadata["dead_code"] = dead_code_json;
                        }
                        // å…±é€šãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ã‚‚ä¿å­˜ï¼ˆã©ã®è¨€èªã§ã‚‚å‚ç…§å¯èƒ½ï¼‰
                        result.file_info.metadata["dead_code"] = dead_code_json;
                        
                        std::cerr << "âœ… Dead code analysis completed for: " << filename << std::endl;
                        
                        // æ¤œå‡ºæ•°ã‚’è¡¨ç¤º
                        if (dead_code_result["dead_code"].contains("total_found")) {
                            int total_found = dead_code_result["dead_code"]["total_found"];
                            if (total_found > 0) {
                                std::cerr << "   ğŸ” Found " << total_found << " dead code items" << std::endl;
                            }
                        }
                    } else {
                        // std::cerr << "âš ï¸ Dead code analysis returned no results for: " << filename << std::endl;
                    }
                } catch (const nlohmann::json::exception& e) {
                    // JSONå‡ºåŠ›ã«å¹²æ¸‰ã™ã‚‹ãŸã‚ç„¡åŠ¹åŒ–
                    // std::cerr << "âš ï¸ Failed to parse dead code analysis JSON: " << e.what() << std::endl;
                }
            }
        } else {
            // std::cerr << "âš ï¸ No JSON output from dead code analysis for: " << filename << std::endl;
        }
        
    } catch (const std::exception& e) {
        std::cerr << "âŒ Complete analysis error: " << e.what() << std::endl;
    }
}

//=============================================================================
// ğŸ“ Directory Analysis
//=============================================================================

Result<DirectoryAnalysis> NekoCodeCore::analyze_directory(const FilePath& directory_path) {
    // ğŸ› TEMPORARY FIX: ä¸¦åˆ—å‡¦ç†ã‚’å¼·åˆ¶ç„¡åŠ¹åŒ–ã—ã¦ã‚»ã‚°ãƒ•ã‚©ãƒ«ãƒˆå›é¿
    if (false && impl_->parallel_enabled_) {
        std::cerr << "ğŸ”„ Using parallel processing path" << std::endl;
        return analyze_directory_parallel(directory_path);
    }
    std::cerr << "ğŸŒ Using sequential processing path" << std::endl;
    
    auto [result, duration] = utils::measure_time([&]() -> Result<DirectoryAnalysis> {
        try {
            DirectoryAnalysis analysis;
            analysis.directory_path = directory_path;
            
            // ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
            auto files = impl_->file_scanner_->scan_directory(directory_path);
            auto js_files = impl_->file_scanner_->filter_files(files);
            
            // é †æ¬¡è§£æ
            for (size_t i = 0; i < js_files.size(); ++i) {
                if (impl_->progress_callback_) {
                    impl_->progress_callback_(
                        static_cast<uint32_t>(i), 
                        static_cast<uint32_t>(js_files.size()), 
                        js_files[i].filename().string()
                    );
                }
                
                auto file_result = analyze_file(js_files[i]);
                if (file_result.is_success()) {
                    analysis.files.push_back(file_result.value());
                }
            }
            
            analysis.update_summary();
            return Result<DirectoryAnalysis>(std::move(analysis));
            
        } catch (const std::exception& e) {
            return Result<DirectoryAnalysis>(AnalysisError(ErrorCode::PARSING_ERROR, e.what()));
        }
    });
    
    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆæ›´æ–°
    {
        std::lock_guard<std::mutex> lock(impl_->metrics_mutex_);
        impl_->metrics_.analysis_time += duration;
    }
    
    return result;
}

Result<DirectoryAnalysis> NekoCodeCore::analyze_directory_parallel(const FilePath& directory_path) {
    auto [result, duration] = utils::measure_time([&]() -> Result<DirectoryAnalysis> {
        try {
            DirectoryAnalysis analysis;
            analysis.directory_path = directory_path;
            
            // ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
            auto files = impl_->file_scanner_->scan_directory(directory_path);
            auto js_files = impl_->file_scanner_->filter_files(files);
            
            // ğŸš€ æ–°ã—ã„ä¸¦åˆ—åŒ–æˆ¦ç•¥: I/Oä¸¦åˆ—åº¦ã¨CPUä¸¦åˆ—åº¦ã‚’åˆ†é›¢
            std::vector<AnalysisResult> results(js_files.size());
            std::vector<bool> success_flags(js_files.size(), false);
            
            // I/Oä¸¦åˆ—åº¦ã‚’åˆ¶é™ã™ã‚‹ãŸã‚ã®ç°¡æ˜“å®Ÿè£…ï¼ˆC++17äº’æ›ï¼‰
            std::atomic<size_t> active_io_count{0};
            const size_t max_io_threads = impl_->io_threads_;
            
            // ãƒ‡ãƒãƒƒã‚°ç”¨: é–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²
            auto start_time = std::chrono::high_resolution_clock::now();
            
            // CPUä¸¦åˆ—åº¦ã®åˆ¶å¾¡ï¼ˆexecution policyã§è‡ªå‹•èª¿æ•´ï¼‰
            // TODO: å°†æ¥çš„ã«ã¯thread poolã§ã‚ˆã‚Šç´°ã‹ãåˆ¶å¾¡
            
            // ä¸¦åˆ—å‡¦ç†ç”¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ™ã‚¯ãƒˆãƒ«ä½œæˆ
            std::vector<size_t> indices(js_files.size());
            std::iota(indices.begin(), indices.end(), 0);
            
            std::for_each(std::execution::par_unseq, 
                indices.begin(), indices.end(),
                [&](size_t i) {
                    // I/Oä¸¦åˆ—åº¦åˆ¶é™ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
                    while (active_io_count.load() >= max_io_threads) {
                        std::this_thread::yield();  // å¾…æ©Ÿ
                    }
                    active_io_count.fetch_add(1);
                    
                    // ãƒ•ã‚¡ã‚¤ãƒ«è§£æå®Ÿè¡Œ
                    auto file_result = analyze_file(js_files[i]);
                    
                    // I/Oã‚«ã‚¦ãƒ³ãƒˆæ¸›å°‘
                    active_io_count.fetch_sub(1);
                    
                    if (file_result.is_success()) {
                        results[i] = file_result.value();
                        success_flags[i] = true;
                    }
                });
            
            // æˆåŠŸã—ãŸçµæœã®ã¿åé›†
            for (size_t i = 0; i < results.size(); ++i) {
                if (success_flags[i]) {
                    analysis.files.push_back(std::move(results[i]));
                }
            }
            
            analysis.update_summary();
            
            // ãƒ‡ãƒãƒƒã‚°ç”¨: å‡¦ç†æ™‚é–“ã‚’è¨˜éŒ²
            auto end_time = std::chrono::high_resolution_clock::now();
            auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);
            std::cerr << "ğŸš€ Parallel analysis completed: " 
                      << js_files.size() << " files in " 
                      << duration.count() << "ms with --io-threads=" 
                      << max_io_threads << std::endl;
            
            return Result<DirectoryAnalysis>(std::move(analysis));
            
        } catch (const std::exception& e) {
            return Result<DirectoryAnalysis>(AnalysisError(ErrorCode::PARSING_ERROR, e.what()));
        }
    });
    
    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆæ›´æ–°
    {
        std::lock_guard<std::mutex> lock(impl_->metrics_mutex_);
        impl_->metrics_.analysis_time += duration;
    }
    
    return result;
}

Result<DirectoryAnalysis> NekoCodeCore::analyze_files(const std::vector<FilePath>& file_paths) {
    try {
        DirectoryAnalysis analysis;
        analysis.directory_path = file_paths.empty() ? FilePath(".") : file_paths[0].parent_path();
        
        for (const auto& file_path : file_paths) {
            auto file_result = analyze_file(file_path);
            if (file_result.is_success()) {
                analysis.files.push_back(file_result.value());
            }
        }
        
        analysis.update_summary();
        return Result<DirectoryAnalysis>(std::move(analysis));
        
    } catch (const std::exception& e) {
        return Result<DirectoryAnalysis>(AnalysisError(ErrorCode::PARSING_ERROR, e.what()));
    }
}

//=============================================================================
// ğŸ” File Discovery
//=============================================================================

std::vector<FilePath> NekoCodeCore::scan_javascript_files(const FilePath& directory_path) {
    return impl_->file_scanner_->scan_directory(directory_path);
}

std::vector<FilePath> NekoCodeCore::filter_files(const std::vector<FilePath>& files) {
    return impl_->file_scanner_->filter_files(files);
}

bool NekoCodeCore::should_exclude_file(const FilePath& file_path) const {
    return impl_->file_scanner_->should_exclude(file_path);
}

//=============================================================================
// ğŸ“Š Analysis Components
//=============================================================================

FileInfo NekoCodeCore::analyze_file_structure(const std::string& content, const FilePath& file_path) {
    FileInfo info(file_path);
    
    auto lines = utils::split_lines(content);
    info.total_lines = static_cast<uint32_t>(lines.size());
    info.size_bytes = content.size();
    
    uint32_t code_lines = 0;
    uint32_t comment_lines = 0;
    uint32_t empty_lines = 0;
    
    bool in_block_comment = false;
    
    for (const auto& line : lines) {
        std::string trimmed = utils::trim(line);
        
        if (trimmed.empty()) {
            empty_lines++;
        } else if (trimmed.length() >= 2 && trimmed.substr(0, 2) == "//") {
            comment_lines++;
        } else if (trimmed.length() >= 2 && trimmed.substr(0, 2) == "/*") {
            comment_lines++;
            in_block_comment = !(trimmed.length() >= 2 && trimmed.substr(trimmed.length() - 2) == "*/");
        } else if (in_block_comment) {
            comment_lines++;
            if (trimmed.length() >= 2 && trimmed.substr(trimmed.length() - 2) == "*/") {
                in_block_comment = false;
            }
        } else {
            code_lines++;
        }
    }
    
    info.code_lines = code_lines;
    info.comment_lines = comment_lines;
    info.empty_lines = empty_lines;
    info.code_ratio = info.total_lines > 0 ? 
        static_cast<double>(code_lines) / info.total_lines : 0.0;
    
    return info;
}

std::vector<ClassInfo> NekoCodeCore::analyze_classes(const std::string& content) {
    // ğŸŒ³ Tree-sitterãŒæ—¢ã«ã‚¯ãƒ©ã‚¹è§£ææ¸ˆã¿ - ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼å®Ÿè£…
    (void)content; // æœªä½¿ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è­¦å‘Šå›é¿
    return {}; // ç©ºã®çµæœã‚’è¿”ã™ï¼ˆTree-sitterã§æ—¢ã«å‡¦ç†æ¸ˆã¿ï¼‰
}

std::vector<FunctionInfo> NekoCodeCore::analyze_functions(const std::string& content) {
    // ğŸŒ³ Tree-sitterãŒæ—¢ã«é–¢æ•°è§£ææ¸ˆã¿ - ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼å®Ÿè£…
    (void)content; // æœªä½¿ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è­¦å‘Šå›é¿
    return {}; // ç©ºã®çµæœã‚’è¿”ã™ï¼ˆTree-sitterã§æ—¢ã«å‡¦ç†æ¸ˆã¿ï¼‰
}

std::pair<std::vector<ImportInfo>, std::vector<ExportInfo>> 
NekoCodeCore::analyze_dependencies(const std::string& content) {
    // ğŸŒ³ Tree-sitterãŒæ—¢ã«ä¾å­˜é–¢ä¿‚è§£ææ¸ˆã¿ - ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼å®Ÿè£…
    (void)content; // æœªä½¿ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è­¦å‘Šå›é¿
    return {{}, {}}; // ç©ºã®çµæœã‚’è¿”ã™ï¼ˆTree-sitterã§æ—¢ã«å‡¦ç†æ¸ˆã¿ï¼‰
}

std::pair<std::vector<FunctionCall>, FunctionCallFrequency> 
NekoCodeCore::analyze_function_calls(const std::string& content) {
    // ğŸŒ³ Tree-sitterãŒæ—¢ã«é–¢æ•°å‘¼ã³å‡ºã—è§£ææ¸ˆã¿ - ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼å®Ÿè£…
    (void)content; // æœªä½¿ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è­¦å‘Šå›é¿
    return {{}, {}}; // ç©ºã®çµæœã‚’è¿”ã™ï¼ˆTree-sitterã§æ—¢ã«å‡¦ç†æ¸ˆã¿ï¼‰
}

ComplexityInfo NekoCodeCore::analyze_complexity(const std::string& content) {
    // ğŸŒ³ Tree-sitterãŒæ—¢ã«è¤‡é›‘åº¦è§£ææ¸ˆã¿ - ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼å®Ÿè£…
    (void)content; // æœªä½¿ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è­¦å‘Šå›é¿
    
    ComplexityInfo complexity;
    complexity.cyclomatic_complexity = 1; // åŸºæœ¬å€¤
    complexity.cognitive_complexity = 0;
    complexity.max_nesting_depth = 0;
    complexity.update_rating();
    
    return complexity;
}

//=============================================================================
// âš™ï¸ Configuration & Settings
//=============================================================================

void NekoCodeCore::set_config(const AnalysisConfig& config) {
    impl_->config_ = config;
    impl_->file_scanner_ = std::make_unique<FileScanner>(config);
}

const AnalysisConfig& NekoCodeCore::get_config() const {
    return impl_->config_;
}

void NekoCodeCore::enable_parallel_processing(bool enabled) {
    impl_->parallel_enabled_ = enabled;
}

void NekoCodeCore::set_thread_count(std::uint32_t count) {
    impl_->thread_count_ = count;
}

//=============================================================================
// ğŸ“ˆ Performance & Monitoring
//=============================================================================

const PerformanceMetrics& NekoCodeCore::get_performance_metrics() const {
    std::lock_guard<std::mutex> lock(impl_->metrics_mutex_);
    return impl_->metrics_;
}

void NekoCodeCore::reset_performance_metrics() {
    std::lock_guard<std::mutex> lock(impl_->metrics_mutex_);
    impl_->metrics_ = PerformanceMetrics{};
}

void NekoCodeCore::set_progress_callback(ProgressCallback callback) {
    impl_->progress_callback_ = callback;
}

//=============================================================================
// ğŸŒ Multi-Language Support Implementation
//=============================================================================

const LanguageDetector& NekoCodeCore::get_language_detector() const {
    return *impl_->language_detector_;
}

const CppAnalyzer& NekoCodeCore::get_cpp_analyzer() const {
    return *impl_->cpp_analyzer_;
}

std::vector<Language> NekoCodeCore::get_supported_languages() const {
    return impl_->language_detector_->get_supported_languages();
}

std::vector<FilePath> NekoCodeCore::scan_supported_files(const FilePath& directory_path) {
    std::vector<FilePath> all_files;
    
    try {
        for (const auto& entry : std::filesystem::recursive_directory_iterator(directory_path)) {
            if (entry.is_regular_file()) {
                Language detected = impl_->language_detector_->detect_by_extension(entry.path());
                if (detected != Language::UNKNOWN && !should_exclude_file(entry.path())) {
                    all_files.push_back(entry.path());
                }
            }
        }
    } catch (const std::filesystem::filesystem_error&) {
        // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
    }
    
    return all_files;
}

std::vector<FilePath> NekoCodeCore::scan_files_for_language(const FilePath& directory_path, Language language) {
    std::vector<FilePath> language_files;
    auto extensions = impl_->language_detector_->get_extensions_for_language(language);
    
    try {
        for (const auto& entry : std::filesystem::recursive_directory_iterator(directory_path)) {
            if (entry.is_regular_file()) {
                std::string ext = entry.path().extension().string();
                std::transform(ext.begin(), ext.end(), ext.begin(), ::tolower);
                
                if (std::find(extensions.begin(), extensions.end(), ext) != extensions.end() &&
                    !should_exclude_file(entry.path())) {
                    language_files.push_back(entry.path());
                }
            }
        }
    } catch (const std::filesystem::filesystem_error&) {
        // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
    }
    
    return language_files;
}

std::unordered_map<Language, std::vector<FilePath>> NekoCodeCore::classify_files_by_language(const std::vector<FilePath>& files) {
    std::unordered_map<Language, std::vector<FilePath>> classified;
    
    for (const auto& file : files) {
        Language detected = impl_->language_detector_->detect_by_extension(file);
        classified[detected].push_back(file);
    }
    
    return classified;
}



















//=============================================================================
// ğŸ§® Complexity Calculator Implementation  
//=============================================================================

const std::vector<std::string> ComplexityCalculator::control_keywords_ = {
    "if", "else", "while", "for", "do", "switch", "case", "catch", "try",
    "&&", "||", "?", ":", "return"
};

std::uint32_t ComplexityCalculator::calculate_cyclomatic_complexity(const std::string& content) {
    std::uint32_t complexity = 1; // åŸºæœ¬ãƒ‘ã‚¹
    
    for (const auto& keyword : control_keywords_) {
        std::regex keyword_regex("\\b" + keyword + "\\b");
        std::sregex_iterator iter(content.begin(), content.end(), keyword_regex);
        std::sregex_iterator end;
        
        complexity += std::distance(iter, end);
    }
    
    return complexity;
}

std::uint32_t ComplexityCalculator::calculate_cognitive_complexity(const std::string& content) {
    std::uint32_t cognitive = 0;
    std::uint32_t nesting_level = 0;
    
    // ç°¡æ˜“å®Ÿè£…: ãƒã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ã‚’è€ƒæ…®ã—ãŸè¤‡é›‘åº¦
    auto lines = utils::split_lines(content);
    
    for (const auto& line : lines) {
        std::string trimmed = utils::trim(line);
        
        // ãƒã‚¹ãƒˆãƒ¬ãƒ™ãƒ«æ›´æ–°
        if (trimmed.find('{') != std::string::npos) {
            nesting_level++;
        }
        if (trimmed.find('}') != std::string::npos && nesting_level > 0) {
            nesting_level--;
        }
        
        // åˆ¶å¾¡æ§‹é€ æ¤œå‡º
        for (const auto& keyword : control_keywords_) {
            if (trimmed.find(keyword) != std::string::npos) {
                cognitive += (1 + nesting_level); // ãƒã‚¹ãƒˆãƒ¬ãƒ™ãƒ«åˆ†ãƒšãƒŠãƒ«ãƒ†ã‚£
                break;
            }
        }
    }
    
    return cognitive;
}

std::uint32_t ComplexityCalculator::calculate_max_nesting_depth(const std::string& content) {
    std::uint32_t max_depth = 0;
    std::uint32_t current_depth = 0;
    
    for (char c : content) {
        if (c == '{') {
            current_depth++;
            max_depth = std::max(max_depth, current_depth);
        } else if (c == '}' && current_depth > 0) {
            current_depth--;
        }
    }
    
    return max_depth;
}

//=============================================================================
// ğŸ“„ File Scanner Implementation
//=============================================================================

FileScanner::FileScanner(const AnalysisConfig& config) : config_(config) {}

std::vector<FilePath> FileScanner::scan_directory(const FilePath& directory_path) {
    std::vector<FilePath> files;
    
    try {
        for (const auto& entry : std::filesystem::recursive_directory_iterator(directory_path)) {
            if (entry.is_regular_file() && 
                is_javascript_file(entry.path()) && 
                !should_exclude(entry.path())) {
                files.push_back(entry.path());
                stats_.javascript_files++;
            }
            stats_.total_files_found++;
        }
    } catch (const std::filesystem::filesystem_error&) {
        // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
    }
    
    return files;
}

std::vector<FilePath> FileScanner::scan_directory_parallel(const FilePath& directory_path) {
    // å˜ç´”å®Ÿè£…: ç¾åœ¨ã¯é€šå¸¸ã®ã‚¹ã‚­ãƒ£ãƒ³ã¨åŒã˜
    // æœ¬æ ¼å®Ÿè£…ã§ã¯ä¸¦åˆ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªèµ°æŸ»ãŒå¿…è¦
    return scan_directory(directory_path);
}

bool FileScanner::is_javascript_file(const FilePath& file_path) const {
    std::string extension = file_path.extension().string();
    
    return std::find(config_.included_extensions.begin(), 
                    config_.included_extensions.end(), 
                    extension) != config_.included_extensions.end();
}

bool FileScanner::should_exclude(const FilePath& file_path) const {
    std::string path_str = file_path.string();
    
    for (const auto& pattern : config_.excluded_patterns) {
        if (wildcard_match(pattern, path_str)) {
            return true;
        }
    }
    
    return false;
}

bool FileScanner::is_file_too_large(const FilePath& file_path, FileSize max_size) const {
    try {
        return std::filesystem::file_size(file_path) > max_size;
    } catch (const std::filesystem::filesystem_error&) {
        return true; // ã‚¨ãƒ©ãƒ¼æ™‚ã¯å¤§ãã™ãã‚‹ã¨åˆ¤å®š
    }
}

std::vector<FilePath> FileScanner::filter_files(const std::vector<FilePath>& files) {
    std::vector<FilePath> filtered_files;
    for (const auto& file : files) {
        if (is_javascript_file(file) && !should_exclude(file)) {
            filtered_files.push_back(file);
        }
    }
    return filtered_files;
}

bool FileScanner::wildcard_match(const std::string& pattern, const std::string& text) const {
    // ç°¡æ˜“ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
    return text.find(pattern) != std::string::npos;
}

//=============================================================================
// ğŸ¯ Utility Functions Implementation
//=============================================================================

namespace utils {

std::string trim(const std::string& str) {
    size_t start = str.find_first_not_of(" \t\r\n");
    if (start == std::string::npos) return "";
    
    size_t end = str.find_last_not_of(" \t\r\n");
    return str.substr(start, end - start + 1);
}

std::vector<std::string> split_lines(const std::string& content) {
    std::vector<std::string> lines;
    std::stringstream ss(content);
    std::string line;
    
    while (std::getline(ss, line)) {
        lines.push_back(line);
    }
    
    return lines;
}

std::string remove_comments(const std::string& content) {
    std::string result = content;
    
    // å˜è¡Œã‚³ãƒ¡ãƒ³ãƒˆå‰Šé™¤
    std::regex single_comment_regex(R"(//.*$)", std::regex_constants::multiline);
    result = std::regex_replace(result, single_comment_regex, "");
    
    // è¤‡æ•°è¡Œã‚³ãƒ¡ãƒ³ãƒˆå‰Šé™¤
    std::regex multi_comment_regex(R"(/\*[\s\S]*?\*/)");
    result = std::regex_replace(result, multi_comment_regex, "");
    
    return result;
}

std::string remove_string_literals(const std::string& content) {
    std::string result = content;
    
    // æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«å‰Šé™¤ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
    std::regex string_regex(R"(["'][^"']*["'])");
    result = std::regex_replace(result, string_regex, "");
    
    return result;
}

Result<std::string> read_file(const FilePath& file_path) {
    try {
        std::ifstream file(file_path, std::ios::binary);
        if (!file.is_open()) {
            return Result<std::string>(AnalysisError(ErrorCode::FILE_NOT_FOUND, 
                "Cannot open file: " + file_path.string()));
        }
        
        file.seekg(0, std::ios::end);
        size_t size = file.tellg();
        file.seekg(0, std::ios::beg);
        
        std::string content(size, '\0');
        file.read(&content[0], size);
        
        return Result<std::string>(std::move(content));
        
    } catch (const std::exception& e) {
        return Result<std::string>(AnalysisError(ErrorCode::UNKNOWN_ERROR, e.what()));
    }
}

Result<FileInfo> get_basic_file_info(const FilePath& file_path) {
    try {
        FileInfo info(file_path);
        
        if (!std::filesystem::exists(file_path)) {
            return Result<FileInfo>(AnalysisError(ErrorCode::FILE_NOT_FOUND, 
                "File not found: " + file_path.string()));
        }
        
        info.size_bytes = std::filesystem::file_size(file_path);
        
        // ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã—ã¦è¡Œæ•°ã‚«ã‚¦ãƒ³ãƒˆ
        auto content_result = read_file(file_path);
        if (content_result.is_error()) {
            return Result<FileInfo>(content_result.error());
        }
        
        auto lines = split_lines(content_result.value());
        info.total_lines = static_cast<uint32_t>(lines.size());
        
        return Result<FileInfo>(std::move(info));
        
    } catch (const std::exception& e) {
        return Result<FileInfo>(AnalysisError(ErrorCode::UNKNOWN_ERROR, e.what()));
    }
}

std::string format_timestamp(const Timestamp& timestamp) {
    auto time = std::chrono::system_clock::to_time_t(timestamp);
    std::stringstream ss;
    ss << std::put_time(std::localtime(&time), "%Y-%m-%d %H:%M:%S");
    return ss.str();
}

std::string format_file_size(FileSize size) {
    const char* units[] = {"B", "KB", "MB", "GB"};
    double file_size = static_cast<double>(size);
    int unit_index = 0;
    
    while (file_size >= 1024.0 && unit_index < 3) {
        file_size /= 1024.0;
        unit_index++;
    }
    
    std::stringstream ss;
    ss << std::fixed << std::setprecision(1) << file_size << " " << units[unit_index];
    return ss.str();
}

} // namespace utils

} // namespace nekocode